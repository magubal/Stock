# [Design] Stock Moat Estimator

> **Feature**: stock-moat-estimator
> **Phase**: Design
> **Created**: 2026-02-09
> **Plan Reference**: `docs/01-plan/features/stock-moat-estimator.plan.md`
> **Status**: In Progress

---

## 1. Agent Architecture

### 1.1 Agent Specification

**Agent Name**: `stock-moat-estimator`

**Agent Definition File**: `.agent/agents/stock-moat-estimator/agent.json`

```json
{
  "name": "stock-moat-estimator",
  "description": "Specialized agent for analyzing Korean stock moats and core business sectors",
  "version": "1.0.0",
  "model": "claude-sonnet-4-5",
  "fallback_model": "claude-haiku-4-5",
  "capabilities": [
    "korean-corporate-disclosure-analysis",
    "moat-strength-evaluation",
    "sector-classification",
    "competitive-analysis",
    "batch-processing"
  ],
  "knowledge_domains": [
    "Korean corporate disclosures (DART, KIND)",
    "229 sector taxonomy (Korean business classifications)",
    "Economic moat framework (5 categories)",
    "Investment philosophy (docs/investment-philosophy.md)",
    "Korean financial terminology"
  ],
  "tools": [
    "WebFetch",
    "Grep",
    "Read",
    "Write",
    "Bash"
  ],
  "memory": {
    "scope": "project",
    "path": ".agent/memory/stock-moat-estimator/",
    "persistent": true
  },
  "quality_thresholds": {
    "moat_verification_required": 4,
    "min_source_citations": 2,
    "max_tokens_per_stock": 10000
  }
}
```

### 1.2 Agent Knowledge Base

**Directory**: `.agent/memory/stock-moat-estimator/`

```
.agent/memory/stock-moat-estimator/
â”œâ”€â”€ KNOWLEDGE.md                    # Core domain knowledge
â”œâ”€â”€ sector_patterns.md              # Industry-specific moat patterns
â”œâ”€â”€ moat_examples.md                # Reference analyses (learning)
â”œâ”€â”€ error_corrections.md            # Quality improvements log
â”œâ”€â”€ research_sources.md             # Reliable data sources catalog
â””â”€â”€ taxonomy_mapping.json           # 229 sector â†’ business mapping
```

**KNOWLEDGE.md Structure**:
```markdown
# Stock Moat Estimator Knowledge Base

## Data Sources (Priority Order)
1. DART (dart.fss.or.kr) - ì‚¬ì—…ë³´ê³ ì„œ, ë¶„ê¸°ë³´ê³ ì„œ
2. KIND (kind.krx.co.kr) - ê¸°ì—…ê°œìš”, ì¬ë¬´ì •ë³´
3. Company IR - íˆ¬ìì ì •ë³´, ê¸°ì—… ì†Œê°œ
4. ì¦ê¶Œë³´ê³ ì„œ - ìƒì„¸ ì¬ë¬´/ì‚¬ì—… ë¶„ì„
5. Naver Finance - ë‰´ìŠ¤, ê³µì‹œ ìš”ì•½

## Moat Framework (5 Categories)
- ë¸Œëœë“œ íŒŒì›Œ (Brand Power): 1-5 scale
- ì›ê°€ ìš°ìœ„ (Cost Advantage): 1-5 scale
- ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ (Network Effects): 1-5 scale
- ì „í™˜ ë¹„ìš© (Switching Costs): 1-5 scale
- ê·œì œ/í—ˆê°€ (Regulatory Moat): 1-5 scale

## Sector Taxonomy Rules
- MUST use only 229 approved Korean names
- NO English names in core_sector_top
- core_sector_sub format: "category/subcategory"
```

### 1.3 Agent Prompts

**System Prompt Template** (`.agent/agents/stock-moat-estimator/system_prompt.md`):

```markdown
You are a specialized stock moat analyst for Korean companies. Your expertise:

1. **Data Sources**: DART, KIND, IR materials, ì¦ê¶Œë³´ê³ ì„œ
2. **Analysis Framework**:
   - Identify core business (ë³¸ì—…) from disclosures
   - Map to 229 Korean sector categories (NO English)
   - Evaluate moat strength (1-5 scale, 5 categories)
   - Re-verify if moat â‰¥ 4 (mandatory quality gate)

3. **Output Requirements**:
   - Cite sources for all claims
   - Use structured format (see examples)
   - Korean language only
   - No speculation; facts only

4. **Quality Standards**:
   - Accuracy > Speed
   - Re-verify high moat scores (â‰¥4)
   - Learn from corrections in error_corrections.md
```

---

## 2. Skill API Design

### 2.1 Skill Definition

**Skill Name**: `/stock-moat`

**Skill File**: `.agent/skills/stock-moat/skill.json`

```json
{
  "name": "stock-moat",
  "description": "Analyze stock moat strength and core business sectors",
  "version": "1.0.0",
  "commands": {
    "analyze": {
      "description": "Analyze single stock",
      "args": ["ticker"],
      "example": "/stock-moat analyze 005930"
    },
    "batch": {
      "description": "Batch process multiple stocks",
      "args": ["--all", "--range {start}-{end}"],
      "example": "/stock-moat batch --range 1-50"
    },
    "verify": {
      "description": "Re-verify high moat stock (â‰¥4)",
      "args": ["ticker"],
      "example": "/stock-moat verify 005930"
    },
    "report": {
      "description": "Generate completion report",
      "args": [],
      "example": "/stock-moat report"
    },
    "status": {
      "description": "Check progress status",
      "args": [],
      "example": "/stock-moat status"
    }
  },
  "agent": "stock-moat-estimator",
  "auto_triggers": [
    "moat analysis",
    "í•´ì ë¶„ì„",
    "ì—…ì¢… ë¶„ë¥˜",
    "sector classification",
    "core business"
  ]
}
```

### 2.2 Command Specifications

#### 2.2.1 `/stock-moat analyze {ticker}`

**Purpose**: Analyze a single stock and fill all missing fields

**Workflow**:
```
1. Load stock data from Excel (ticker row)
2. Check if already complete (skip if filled)
3. Research workflow:
   a. Fetch DART ì‚¬ì—…ë³´ê³ ì„œ
   b. Identify core business
   c. Classify sector (229 taxonomy)
   d. Evaluate moat (5 categories)
   e. If moat â‰¥ 4 â†’ trigger verify
4. Write results to Excel (atomic update)
5. Log completion status
```

**Input**: Stock ticker (6-digit code or name)

**Output**: Updated Excel row with all fields filled

**Example Usage**:
```bash
/stock-moat analyze 005930        # Samsung Electronics
/stock-moat analyze ë„¤ì˜¤ìœ„ì¦ˆ        # By name
```

---

#### 2.2.2 `/stock-moat batch --all` or `--range {start}-{end}`

**Purpose**: Process multiple stocks in parallel batches

**Workflow**:
```
1. Load incomplete stocks list (196 stocks)
2. Split into batches of 10 stocks
3. For each batch:
   a. Process 10 stocks in parallel
   b. Checkpoint after each batch
   c. Log progress to .stock-moat-status.json
4. Generate batch completion report
```

**Arguments**:
- `--all`: Process all 196 incomplete stocks
- `--range {start}-{end}`: Process rows start to end (e.g., 1-50)

**Example Usage**:
```bash
/stock-moat batch --all             # All 196 stocks
/stock-moat batch --range 1-50      # First 50 stocks
```

**Batch Processing Strategy**:
```python
# Parallel execution (10 concurrent)
batch_size = 10
batches = split_stocks_into_batches(incomplete_stocks, batch_size)

for batch_idx, batch in enumerate(batches):
    # Process 10 stocks in parallel
    results = parallel_process(batch, analyze_stock)

    # Checkpoint progress
    checkpoint(batch_idx, results)

    # Estimate: 5 min per batch â†’ 20 batches Ã— 5 = 100 min (1.7 hours)
```

---

#### 2.2.3 `/stock-moat verify {ticker}`

**Purpose**: Re-verify high moat stocks (â‰¥4) with deeper research

**Workflow**:
```
1. Load stock with moat â‰¥ 4
2. Deep research:
   a. Cross-reference multiple sources
   b. Analyze competitors
   c. Validate moat sustainability
3. Update ê²€ì¦ìš©desc with verification details
4. Adjust moat score if needed
```

**Quality Gate**: Mandatory for all stocks with initial moat â‰¥ 4

**Example Usage**:
```bash
/stock-moat verify 005930
```

---

#### 2.2.4 `/stock-moat report`

**Purpose**: Generate analysis completion report

**Output**: `docs/04-report/stock-moat-estimator.report.md`

**Report Contents**:
- Completion statistics (208/208)
- Moat strength distribution (1-5 histogram)
- Sector breakdown (top 10 sectors)
- High moat stocks (â‰¥4) list with verification status
- Quality metrics (avg tokens/stock, error rate)

---

#### 2.2.5 `/stock-moat status`

**Purpose**: Check current progress

**Output**:
```
ğŸ“Š Stock Moat Analysis Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Stocks: 208
Completed: 45 / 208 (21.6%)
Remaining: 163
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Current Batch: 5 / 20
Moat â‰¥4 (Need Verification): 8
Verified: 5 / 8
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Estimated Time Remaining: 80 min
```

---

## 3. Data Schema & Excel I/O

### 3.1 Excel File Structure

**File**: `data/ask/stock_core_master_v2_korean_taxonomy_2026-01-30_ìš”ì²­ìš©_011.xlsx`

**Sheets**:
1. `stock_core_master` - Main data (208 rows)
2. `schema` - Field definitions
3. `ë¶„ë¥˜ìœ í˜•(ì°¸ê³ )` - 229 sector taxonomy
4. `TODO` - Requirements
5. `change_log` - Modification history

### 3.2 stock_core_master Schema

| Field | Type | Description | Validation |
|-------|------|-------------|------------|
| `ticker` | String(6) | Stock code | Required, unique |
| `name` | String | Company name | Required |
| `core_sector_top` | String | ì—…ì¢… ë¶„ë¥˜ (ìƒìœ„) | Must be from 229 approved list |
| `core_sector_sub` | String | ì—…ì¢… ë¶„ë¥˜ (í•˜ìœ„) | Format: "cat/subcat" |
| `core_desc` | Text | ë³¸ì—… ì„¤ëª… (1-3ì¤„) | Min 20 chars |
| `í•´ìê°•ë„` | Integer | Moat strength (1-5) | Range: 1-5 |
| `í•´ìDESC` | Text | Moat category breakdown | Structured format (see below) |
| `moat_name` | String | (Deprecated) | Legacy field |
| `desc` | Text | (Deprecated) | Legacy field |
| `ê²€ì¦ìš©desc` | Text | Re-verification notes | Required if í•´ìê°•ë„ â‰¥ 4 |

### 3.3 í•´ìDESC Format Specification

**Structure**:
```
ë¸Œëœë“œ íŒŒì›Œ: {score}/5 ({brief_reason})
ì›ê°€ ìš°ìœ„: {score}/5 ({brief_reason})
ë„¤íŠ¸ì›Œí¬ íš¨ê³¼: {score}/5 ({brief_reason})
ì „í™˜ ë¹„ìš©: {score}/5 ({brief_reason})
ê·œì œ/í—ˆê°€: {score}/5 ({brief_reason})
---
ì´ì : {sum}/25 â†’ í•´ìê°•ë„ {final_score}
```

**Example**:
```
ë¸Œëœë“œ íŒŒì›Œ: 4/5 (êµ­ë‚´ 1ìœ„ ë¸Œëœë“œ ì¸ì§€ë„)
ì›ê°€ ìš°ìœ„: 3/5 (ì¤‘ê·œëª¨ ìƒì‚°ì‹œì„¤)
ë„¤íŠ¸ì›Œí¬ íš¨ê³¼: 2/5 (ì œí•œì )
ì „í™˜ ë¹„ìš©: 4/5 (ê¸°ì—… ê³ ê° ì¥ê¸° ê³„ì•½)
ê·œì œ/í—ˆê°€: 5/5 (ì˜ë£Œê¸°ê¸° í—ˆê°€ ë³´ìœ )
---
ì´ì : 18/25 â†’ í•´ìê°•ë„ 4
```

**Calculation Logic**:
```python
def calculate_moat_strength(category_scores: dict) -> int:
    """
    category_scores = {
        'brand': 4,
        'cost': 3,
        'network': 2,
        'switching': 4,
        'regulatory': 5
    }
    """
    total = sum(category_scores.values())  # 18
    avg = total / 5  # 3.6
    moat_strength = round(avg)  # 4
    return moat_strength
```

### 3.4 Excel I/O Implementation

**Library**: `pandas` + `openpyxl`

**Read Operation**:
```python
import pandas as pd

def load_stock_data(file_path: str) -> pd.DataFrame:
    """Load stock_core_master sheet"""
    df = pd.read_excel(
        file_path,
        sheet_name='stock_core_master',
        engine='openpyxl'
    )
    return df

def get_incomplete_stocks(df: pd.DataFrame) -> pd.DataFrame:
    """Filter stocks with missing data"""
    incomplete = df[
        df['core_sector_top'].isna() |
        df['í•´ìê°•ë„'].isna()
    ]
    return incomplete  # 196 stocks
```

**Write Operation** (Atomic):
```python
def update_stock_row(
    file_path: str,
    ticker: str,
    data: dict
) -> bool:
    """
    Atomic update of single stock row

    Args:
        ticker: Stock code (e.g., '005930')
        data: {
            'core_sector_top': 'ë°˜ë„ì²´',
            'core_sector_sub': 'ë©”ëª¨ë¦¬/ì‹œìŠ¤í…œë°˜ë„ì²´',
            'core_desc': '...',
            'í•´ìê°•ë„': 5,
            'í•´ìDESC': '...',
            'ê²€ì¦ìš©desc': '...'
        }
    """
    # 1. Create backup
    backup_file = f"{file_path}.backup"
    shutil.copy2(file_path, backup_file)

    try:
        # 2. Load Excel
        with pd.ExcelFile(file_path, engine='openpyxl') as xls:
            df = pd.read_excel(xls, sheet_name='stock_core_master')

        # 3. Update row
        row_idx = df[df['ticker'] == ticker].index[0]
        for field, value in data.items():
            df.at[row_idx, field] = value

        # 4. Write back (atomic)
        with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:
            df.to_excel(writer, sheet_name='stock_core_master', index=False)

        # 5. Remove backup if successful
        os.remove(backup_file)
        return True

    except Exception as e:
        # Restore from backup
        shutil.copy2(backup_file, file_path)
        raise e
```

---

## 4. Research Workflow

### 4.1 Single Stock Analysis Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Stock Analysis Workflow                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[1] Load Stock Data
    â†“
    Input: ticker (e.g., '005930')
    Query: df[df['ticker'] == ticker]
    Check: Skip if already complete

[2] Fetch Company Info
    â†“
    Sources (priority order):
    1. DART API: https://opendart.fss.or.kr/api/company.json?crtfc_key={api_key}&corp_code={corp_code}
    2. KIND: http://kind.krx.co.kr/corpgeneral/corpList.do
    3. Naver Finance: https://finance.naver.com/item/main.nhn?code={ticker}
    â†“
    Extract:
    - ì‚¬ì—…ì˜ ë‚´ìš© (business description)
    - ì£¼ìš” ì œí’ˆ ë° ì„œë¹„ìŠ¤ (products/services)
    - ë§¤ì¶œ êµ¬ì„± (revenue breakdown)

[3] Identify Core Business
    â†“
    Analysis:
    - Parse ì‚¬ì—…ë³´ê³ ì„œ "ì‚¬ì—…ì˜ ë‚´ìš©" section
    - Identify primary revenue source (>50% revenue)
    - Map business description to keywords
    â†“
    Output:
    - core_desc (1-3 sentences summary)

[4] Classify Sector
    â†“
    Mapping Process:
    - Load 229 sector taxonomy from 'ë¶„ë¥˜ìœ í˜•(ì°¸ê³ )' sheet
    - Match keywords to sector names
    - Use fuzzy matching if needed
    - Validate: MUST use Korean name only
    â†“
    Output:
    - core_sector_top (e.g., "ë°˜ë„ì²´")
    - core_sector_sub (e.g., "ë©”ëª¨ë¦¬/ì‹œìŠ¤í…œë°˜ë„ì²´")

[5] Evaluate Moat Strength
    â†“
    Framework (5 categories):

    A. ë¸Œëœë“œ íŒŒì›Œ (Brand Power)
       - Consumer recognition
       - Brand loyalty metrics
       - Market share in brand-sensitive segments

    B. ì›ê°€ ìš°ìœ„ (Cost Advantage)
       - Economies of scale
       - Proprietary technology
       - Exclusive access to resources

    C. ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ (Network Effects)
       - Platform dynamics
       - User growth â†’ value growth
       - Multi-sided markets

    D. ì „í™˜ ë¹„ìš© (Switching Costs)
       - Customer lock-in
       - Integration complexity
       - Long-term contracts

    E. ê·œì œ/í—ˆê°€ (Regulatory Moat)
       - Licenses and permits
       - Regulatory barriers to entry
       - Government approvals

    â†“
    Scoring:
    - Each category: 1-5 scale
    - Total: sum(scores) / 5 = avg
    - Round to nearest integer â†’ í•´ìê°•ë„

    â†“
    Output:
    - í•´ìê°•ë„: 1-5
    - í•´ìDESC: structured breakdown

[6] Quality Gate: Re-verification (if í•´ìê°•ë„ â‰¥ 4)
    â†“
    Deep Research:
    - Cross-reference multiple sources
    - Analyze top 3 competitors
    - Validate moat sustainability (3-5 years)
    - Check for structural vs temporary advantages
    â†“
    Verification Questions:
    1. Can competitors easily replicate this advantage?
    2. Is the moat widening or narrowing?
    3. What could destroy this moat?
    â†“
    Output:
    - ê²€ì¦ìš©desc: detailed verification notes
    - Adjusted í•´ìê°•ë„ (if needed)

[7] Write Results to Excel
    â†“
    Atomic Write:
    - Backup file
    - Update row
    - Validate write
    - Remove backup
    â†“
    Log: completion status to .stock-moat-status.json

[8] Update Agent Memory
    â†“
    Learning:
    - Add to moat_examples.md (if exemplary)
    - Update sector_patterns.md (new insights)
    - Log errors to error_corrections.md
```

### 4.2 Batch Processing Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Batch Processing Architecture                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[1] Load Incomplete Stocks
    â†“
    Query: df[df['í•´ìê°•ë„'].isna()]
    Result: 196 stocks

[2] Split into Batches
    â†“
    batch_size = 10
    batches = [stocks[i:i+10] for i in range(0, 196, 10)]
    Total batches: 20

[3] Process Batch (Parallel)
    â†“
    For each batch:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Parallel Executor (10 concurrent tasks)     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Task 1: analyze(stock_1)  [Haiku/Sonnet]   â”‚
    â”‚  Task 2: analyze(stock_2)  [Haiku/Sonnet]   â”‚
    â”‚  Task 3: analyze(stock_3)  [Haiku/Sonnet]   â”‚
    â”‚  ...                                         â”‚
    â”‚  Task 10: analyze(stock_10) [Haiku/Sonnet]  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Model Selection:
    - Use Haiku for simple cases (moat likely < 4)
    - Use Sonnet for complex/large companies
    - Auto-upgrade to Sonnet if Haiku uncertain

[4] Checkpoint Progress
    â†“
    After each batch:
    - Save progress to .stock-moat-status.json
    - Log completed tickers
    - Record errors for retry

    Status File Format:
    {
      "total": 196,
      "completed": 45,
      "failed": 2,
      "in_progress": 10,
      "current_batch": 5,
      "last_updated": "2026-02-09T12:30:00Z",
      "high_moat_stocks": ["005930", "000660", ...],
      "needs_verification": 8
    }

[5] Error Handling
    â†“
    Retry Logic:
    - API failure: retry 3x with exponential backoff
    - Data missing: mark for manual review
    - Rate limit: pause 60s, resume

    Fallback:
    - If DART fails: try KIND
    - If KIND fails: try Naver Finance
    - If all fail: log to manual_review.json

[6] Re-verification Queue
    â†“
    After batch completion:
    - Collect stocks with í•´ìê°•ë„ â‰¥ 4
    - Process verification queue (sequential)
    - Use Sonnet model (higher quality)
    - Update ê²€ì¦ìš©desc

[7] Generate Report
    â†“
    Final report:
    - Completion rate (208/208)
    - Moat distribution histogram
    - Sector breakdown
    - Quality metrics
```

---

## 5. Moat Evaluation Framework (Detailed)

### 5.1 Scoring Rubric

#### ë¸Œëœë“œ íŒŒì›Œ (Brand Power)

| Score | Criteria | Examples |
|-------|----------|----------|
| 5 | ê¸€ë¡œë²Œ í†±í‹°ì–´ ë¸Œëœë“œ, ë…ì ì  ì¸ì§€ë„ | ì‚¼ì„±, í˜„ëŒ€ì°¨ |
| 4 | êµ­ë‚´ 1-2ìœ„ ë¸Œëœë“œ, ê°•í•œ ì¶©ì„±ë„ | ë„¤ì´ë²„, ì¹´ì¹´ì˜¤ |
| 3 | ì¼ë¶€ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì¸ì •ë°›ìŒ | ì¤‘ê²¬ê¸°ì—… ë¸Œëœë“œ |
| 2 | ë¸Œëœë“œ ì¸ì§€ë„ ë‚®ìŒ, ì¼ë¶€ë§Œ ì¸ì§€ | ì†Œí˜•ì£¼ |
| 1 | ë¸Œëœë“œ ë¬´ê´€í•œ ì‚¬ì—… (commoditized) | 2ì°¨ì „ì§€ ì†Œì¬ |

**Indicators**:
- ë¸Œëœë“œ ê°€ì¹˜ í‰ê°€ì•¡ (Interbrand, Brand Finance)
- ì†Œë¹„ì ì„¤ë¬¸ ì¸ì§€ë„ (Top-of-Mind)
- í”„ë¦¬ë¯¸ì—„ ê°€ê²© ì±…ì • ëŠ¥ë ¥ (price premium)

---

#### ì›ê°€ ìš°ìœ„ (Cost Advantage)

| Score | Criteria | Examples |
|-------|----------|----------|
| 5 | ì••ë„ì  ê·œëª¨ì˜ ê²½ì œ, ë…ì ì  ìì› | ì‚¼ì„±ì „ì íŒŒìš´ë“œë¦¬, POSCO ì œì²  |
| 4 | ì—…ê³„ ìµœëŒ€ ìƒì‚°ì‹œì„¤, ìˆ˜ì§ê³„ì—´í™” | í˜„ëŒ€ì œì² , LGí™”í•™ |
| 3 | ì¤‘ê·œëª¨ ì‹œì„¤, ì¼ë¶€ ì›ê°€ ìš°ìœ„ | ì¤‘ê²¬ ì œì¡°ì—… |
| 2 | ì›ê°€ ìš°ìœ„ ì œí•œì  | ì†Œí˜• ì œì¡°ì—… |
| 1 | ì™¸ì£¼ ì˜ì¡´, ì›ê°€ ê²½ìŸë ¥ ì—†ìŒ | ìœ í†µì—… |

**Indicators**:
- COGS (Cost of Goods Sold) / Revenue ratio
- Gross margin vs industry average
- CAPEX ê·œëª¨ (ì§„ì…ì¥ë²½)
- ìƒì‚°ëŠ¥ë ¥ (Capacity) ì—…ê³„ ìˆœìœ„

---

#### ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ (Network Effects)

| Score | Criteria | Examples |
|-------|----------|----------|
| 5 | ê°•ë ¥í•œ í”Œë«í¼, ì‚¬ìš©ì ì¦ê°€ = ê°€ì¹˜ ì¦ê°€ | ì¹´ì¹´ì˜¤í†¡, ë„¤ì´ë²„ |
| 4 | í”Œë«í¼ ë¹„ì¦ˆë‹ˆìŠ¤, ì–‘ë©´ì‹œì¥ | ì¿ íŒ¡, ë°°ë‹¬ì˜ë¯¼ì¡± |
| 3 | ì¼ë¶€ ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ ì¡´ì¬ | ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹° |
| 2 | ì œí•œì  ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ | ë‹¨ë°©í–¥ ì„œë¹„ìŠ¤ |
| 1 | ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ ë¬´ê´€ | ì œì¡°ì—… |

**Indicators**:
- MAU (Monthly Active Users) ì„±ì¥ë¥ 
- Network density (ì‚¬ìš©ìë‹¹ ì—°ê²° ìˆ˜)
- Multi-homing cost (íƒ€ í”Œë«í¼ ë³‘í–‰ ì‚¬ìš© ë¹„ìš©)

---

#### ì „í™˜ ë¹„ìš© (Switching Costs)

| Score | Criteria | Examples |
|-------|----------|----------|
| 5 | ì „í™˜ ê±°ì˜ ë¶ˆê°€ëŠ¥ (ì‹œìŠ¤í…œ ì˜ì¡´) | ERP ì†”ë£¨ì…˜, ì€í–‰ ì½”ì–´ë±…í‚¹ |
| 4 | ì „í™˜ ë¹„ìš© ë†’ìŒ (ì¥ê¸° ê³„ì•½, ê¸°ìˆ  ì˜ì¡´) | B2B SaaS, ë°˜ë„ì²´ ì¥ë¹„ |
| 3 | ì¤‘ê°„ ìˆ˜ì¤€ ì „í™˜ ë¹„ìš© | ë³´í—˜, í†µì‹  |
| 2 | ë‚®ì€ ì „í™˜ ë¹„ìš© | ì†Œë¹„ì¬ |
| 1 | ì „í™˜ ë§¤ìš° ì‰¬ì›€ | Commodities |

**Indicators**:
- í‰ê·  ê³„ì•½ ê¸°ê°„ (B2B)
- Churn rate (ì´íƒˆë¥ )
- Integration complexity (ì‹œìŠ¤í…œ ì—°ë™)
- Data migration cost

---

#### ê·œì œ/í—ˆê°€ (Regulatory Moat)

| Score | Criteria | Examples |
|-------|----------|----------|
| 5 | ë…ì  ë¼ì´ì„ ìŠ¤, íŠ¹í—ˆ ë³´í˜¸ | ì˜ì•½í’ˆ, ì¹´ì§€ë…¸ |
| 4 | ì—„ê²©í•œ í—ˆê°€ í•„ìš”, ì§„ì…ì¥ë²½ ë†’ìŒ | ì˜ë£Œê¸°ê¸°, ê¸ˆìœµ |
| 3 | ì¼ë¶€ ê·œì œ ì¥ë²½ | ê±´ì„¤, ì—ë„ˆì§€ |
| 2 | ê¸°ë³¸ ì¸í—ˆê°€ë§Œ í•„ìš” | ì¼ë°˜ ì œì¡°ì—… |
| 1 | ê·œì œ ì¥ë²½ ì—†ìŒ | IT ì„œë¹„ìŠ¤ |

**Indicators**:
- í—ˆê°€/ë¼ì´ì„ ìŠ¤ ì·¨ë“ ê¸°ê°„
- ê·œì œ ê¸°ê´€ ìˆ˜
- ì‹ ê·œ ì§„ì…ì ìˆ˜ (ìµœê·¼ 3ë…„)

---

### 5.2 Moat Scoring Examples (Detailed)

#### Example 1: ì‚¼ì„±ì „ì (005930)

**Research Sources**:
- DART ì‚¬ì—…ë³´ê³ ì„œ 2024
- KIND ê¸°ì—…ê°œìš”
- ì‚¼ì„±ì „ì IR ìë£Œ

**Core Business**:
```
core_sector_top: ë°˜ë„ì²´
core_sector_sub: ë©”ëª¨ë¦¬/ì‹œìŠ¤í…œë°˜ë„ì²´
core_desc: ë©”ëª¨ë¦¬ ë°˜ë„ì²´(Dë¨, ë‚¸ë“œ), ì‹œìŠ¤í…œë°˜ë„ì²´(íŒŒìš´ë“œë¦¬, AP) ì œì¡°.
           ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬ ì‹œì¥ ì ìœ ìœ¨ 1ìœ„(40%), íŒŒìš´ë“œë¦¬ 2ìœ„(18%).
```

**Moat Analysis**:
```
ë¸Œëœë“œ íŒŒì›Œ: 5/5 (ê¸€ë¡œë²Œ í†±í‹°ì–´ ë¸Œëœë“œ, Interbrand 5ìœ„)
ì›ê°€ ìš°ìœ„: 5/5 (ì´ˆëŒ€ê·œëª¨ fab(CAPEX 50ì¡°/ë…„), ìˆ˜ì§ê³„ì—´í™”)
ë„¤íŠ¸ì›Œí¬ íš¨ê³¼: 3/5 (ê°¤ëŸ­ì‹œ ìƒíƒœê³„, ì œí•œì )
ì „í™˜ ë¹„ìš©: 4/5 (B2B ê³ ê° ê¸°ìˆ  ì˜ì¡´ì„±, ì¥ê¸° ê³µê¸‰ê³„ì•½)
ê·œì œ/í—ˆê°€: 3/5 (ì¼ë°˜ ì‚°ì—…ì¬, íŠ¹í—ˆëŠ” ë§ìœ¼ë‚˜ ë…ì  ì•„ë‹˜)
---
ì´ì : 20/25 â†’ í•´ìê°•ë„ 4
```

**Re-verification** (í•´ìê°•ë„ â‰¥ 4):
```
ê²€ì¦ìš©desc:
ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ì‹œì¥ ì ìœ ìœ¨ 1ìœ„(40%, SKí•˜ì´ë‹‰ìŠ¤ 2ìœ„ 30%).
íŒŒìš´ë“œë¦¬ ì ìœ ìœ¨ 2ìœ„(18%, TSMC 1ìœ„ 60%).
CAPEX 50ì¡°ì›/ë…„ìœ¼ë¡œ ì§„ì…ì¥ë²½ ê·¹ë„ë¡œ ë†’ìŒ (ê²½ìŸì‚¬: 30-40ì¡°).
10nm ì´í•˜ ê³µì • ê¸°ìˆ ë ¥ ê²€ì¦ë¨ (ì¦ê¶Œë³´ê³ ì„œ 2024 í™•ì¸).
â†’ í•´ìê°•ë„ 4 ìœ ì§€ (5ë¡œ ìƒí–¥ ê²€í† í–ˆìœ¼ë‚˜, íŒŒìš´ë“œë¦¬ ì ìœ ìœ¨ ê³ ë ¤ì‹œ 4 ì ì •)
```

---

#### Example 2: ë„¤ì˜¤ìœ„ì¦ˆ (095660) - ì¤‘ì†Œí˜• ê²Œì„ì‚¬

**Research Sources**:
- DART ì‚¬ì—…ë³´ê³ ì„œ 2024
- KIND ê¸°ì—…ê°œìš”
- ë„¤ì˜¤ìœ„ì¦ˆ IR

**Core Business**:
```
core_sector_top: ê²Œì„
core_sector_sub: ëª¨ë°”ì¼ ê²Œì„/PCê²Œì„
core_desc: ëª¨ë°”ì¼ ê²Œì„(ë¸Œë¼ìš´ë”ìŠ¤íŠ¸2, í´ë¡œì €ìŠ¤), PCê²Œì„(ë¸”ë ˆì†Œ, DJë§¥ìŠ¤) ê°œë°œ/í¼ë¸”ë¦¬ì‹±.
           ë§¤ì¶œ êµ¬ì„±: ëª¨ë°”ì¼ 60%, PC 30%, ê¸°íƒ€ 10%.
```

**Moat Analysis**:
```
ë¸Œëœë“œ íŒŒì›Œ: 2/5 (ì¼ë¶€ ê²Œì„ IP ë³´ìœ í•˜ë‚˜ ì¸ì§€ë„ ì œí•œì )
ì›ê°€ ìš°ìœ„: 1/5 (ì™¸ì£¼ ê°œë°œ ì˜ì¡´, ìì²´ ì—”ì§„ ì—†ìŒ)
ë„¤íŠ¸ì›Œí¬ íš¨ê³¼: 3/5 (ì˜¨ë¼ì¸ ê²Œì„ ìœ ì € ì»¤ë®¤ë‹ˆí‹°, ì œí•œì )
ì „í™˜ ë¹„ìš©: 1/5 (ê²Œì„ ì´íƒˆ ì‰¬ì›€, ìœ ì € ì¶©ì„±ë„ ë‚®ìŒ)
ê·œì œ/í—ˆê°€: 2/5 (ê²Œì„ë¬¼ë“±ê¸‰ì‹¬ì˜ë§Œ í•„ìš”, ì§„ì…ì¥ë²½ ë‚®ìŒ)
---
ì´ì : 9/25 â†’ í•´ìê°•ë„ 2
```

**No Re-verification** (í•´ìê°•ë„ < 4)

---

## 6. Data Sources & API Integration

### 6.1 DART API (ê¸ˆìœµê°ë…ì› ì „ìê³µì‹œì‹œìŠ¤í…œ)

**Base URL**: `https://opendart.fss.or.kr`

**API Key**: Required (í™˜ê²½ë³€ìˆ˜ `DART_API_KEY`)

**Key Endpoints**:

1. **Company Info** (`/api/company.json`)
   ```
   GET /api/company.json?crtfc_key={api_key}&corp_code={corp_code}

   Response:
   {
     "corp_name": "ì‚¼ì„±ì „ì",
     "corp_code": "00126380",
     "stock_code": "005930",
     "ceo_nm": "í•œì¢…í¬",
     "corp_cls": "Y",
     "jurir_no": "1301110006246",
     "bizr_no": "1248100998",
     "adres": "ê²½ê¸°ë„ ìˆ˜ì›ì‹œ ì˜í†µêµ¬ ì‚¼ì„±ë¡œ 129",
     "hm_url": "www.samsung.com",
     "ir_url": "https://www.samsung.com/sec/ir/",
     "phn_no": "031-200-1114",
     "fax_no": "031-200-7538",
     "induty_code": "264",
     "est_dt": "19690113"
   }
   ```

2. **Business Report** (`/api/fnlttSinglAcntAll.json`)
   ```
   GET /api/fnlttSinglAcntAll.json?crtfc_key={api_key}&corp_code={corp_code}&bsns_year=2024&reprt_code=11011

   Response: Financial statements + ì‚¬ì—…ì˜ ë‚´ìš© section
   ```

**Usage in Agent**:
```python
def fetch_dart_business_description(corp_code: str) -> str:
    """Fetch ì‚¬ì—…ì˜ ë‚´ìš© from DART"""
    url = f"https://opendart.fss.or.kr/api/company.json"
    params = {
        "crtfc_key": os.getenv("DART_API_KEY"),
        "corp_code": corp_code
    }
    response = requests.get(url, params=params)
    data = response.json()

    # Extract business description
    business_desc = data.get('business_summary', '')
    return business_desc
```

### 6.2 KIND API (í•œêµ­ê±°ë˜ì†Œ ê¸°ì—…ì •ë³´)

**Base URL**: `http://kind.krx.co.kr`

**No API Key Required** (public data)

**Web Scraping Endpoints**:

1. **Company Overview**:
   ```
   URL: http://kind.krx.co.kr/corpgeneral/corpList.do?method=loadInitPage

   Search: ticker or name
   Extract: ì—…ì¢…, ì£¼ìš”ì œí’ˆ, ì‚¬ì—…ë‚´ìš©
   ```

**Usage in Agent**:
```python
def fetch_kind_company_info(ticker: str) -> dict:
    """Scrape KIND for company info"""
    url = "http://kind.krx.co.kr/corpgeneral/corpList.do"
    params = {"method": "loadInitPage"}

    # Use BeautifulSoup to parse HTML
    response = requests.get(url, params=params)
    soup = BeautifulSoup(response.content, 'html.parser')

    # Extract fields
    industry = soup.find('td', text='ì—…ì¢…').find_next('td').text
    products = soup.find('td', text='ì£¼ìš”ì œí’ˆ').find_next('td').text

    return {
        'industry': industry,
        'products': products
    }
```

### 6.3 Company IR Pages

**Strategy**: Use WebFetch tool to fetch IR pages

**Common Patterns**:
- Samsung: `https://www.samsung.com/sec/ir/`
- Naver: `https://ir.navercorp.com/`
- Kakao: `https://ir.kakaocorp.com/`

**Usage**:
```python
# In agent workflow
ir_url = company_data.get('ir_url')
if ir_url:
    content = WebFetch(ir_url, "Extract business description and key products")
```

---

## 7. Progress Tracking & Checkpointing

### 7.1 Status File Structure

**File**: `.stock-moat-status.json`

```json
{
  "version": "1.0.0",
  "last_updated": "2026-02-09T14:30:00Z",
  "total_stocks": 208,
  "completed_stocks": 45,
  "failed_stocks": 2,
  "in_progress_stocks": 10,
  "batches": {
    "total": 20,
    "current": 5,
    "completed": 4
  },
  "high_moat_stocks": [
    "005930",
    "000660",
    "035720"
  ],
  "verification_queue": [
    {
      "ticker": "005930",
      "moat_strength": 4,
      "verified": true,
      "verified_at": "2026-02-09T13:00:00Z"
    }
  ],
  "failed_stocks_log": [
    {
      "ticker": "123456",
      "error": "DART API timeout",
      "retry_count": 3,
      "last_attempt": "2026-02-09T12:00:00Z"
    }
  ],
  "metrics": {
    "avg_tokens_per_stock": 8500,
    "avg_time_per_stock": "4.2 min",
    "total_api_calls": 450,
    "cache_hit_rate": 0.35
  }
}
```

### 7.2 Checkpointing Logic

```python
def checkpoint_progress(batch_idx: int, results: list):
    """Save progress after each batch"""
    status = load_status('.stock-moat-status.json')

    # Update completed stocks
    for result in results:
        if result['success']:
            status['completed_stocks'] += 1
        else:
            status['failed_stocks'] += 1
            status['failed_stocks_log'].append(result['error_info'])

    # Update batch progress
    status['batches']['current'] = batch_idx + 1
    status['batches']['completed'] = batch_idx

    # Update high moat queue
    for result in results:
        if result.get('moat_strength', 0) >= 4:
            status['high_moat_stocks'].append(result['ticker'])
            status['verification_queue'].append({
                'ticker': result['ticker'],
                'moat_strength': result['moat_strength'],
                'verified': False
            })

    # Save status
    save_status('.stock-moat-status.json', status)
```

---

## 8. Error Handling & Retry Strategy

### 8.1 Error Categories

| Error Type | Severity | Retry Strategy | Fallback |
|------------|----------|----------------|----------|
| DART API timeout | Medium | 3x exponential backoff | Try KIND |
| KIND scraping failure | Medium | 2x retry | Try Naver Finance |
| Excel write failure | High | 5x retry + backup | Alert user |
| Sector mapping failure | Low | Manual review | Use "ê¸°íƒ€" category |
| Rate limit (429) | Low | Wait 60s, retry | Continue next batch |

### 8.2 Retry Implementation

```python
def fetch_with_retry(
    fetch_func,
    max_retries=3,
    backoff_factor=2
):
    """Exponential backoff retry"""
    for attempt in range(max_retries):
        try:
            return fetch_func()
        except (Timeout, ConnectionError) as e:
            if attempt == max_retries - 1:
                raise
            wait_time = backoff_factor ** attempt
            time.sleep(wait_time)
            continue
```

### 8.3 Fallback Chain

```
DART API â†’ KIND Scraping â†’ Naver Finance â†’ Manual Review
```

---

## 9. Implementation Files Structure

### 9.1 Directory Layout

```
.agent/
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ stock-moat-estimator/
â”‚       â”œâ”€â”€ agent.json                  # Agent definition
â”‚       â”œâ”€â”€ system_prompt.md            # System prompt
â”‚       â””â”€â”€ config.yml                  # Agent config
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ stock-moat-estimator/
â”‚       â”œâ”€â”€ KNOWLEDGE.md                # Core knowledge
â”‚       â”œâ”€â”€ sector_patterns.md          # Industry patterns
â”‚       â”œâ”€â”€ moat_examples.md            # Reference analyses
â”‚       â”œâ”€â”€ error_corrections.md        # Quality log
â”‚       â”œâ”€â”€ research_sources.md         # Data sources
â”‚       â””â”€â”€ taxonomy_mapping.json       # 229 sector mapping
â”œâ”€â”€ skills/
â”‚   â””â”€â”€ stock-moat/
â”‚       â”œâ”€â”€ skill.json                  # Skill definition
â”‚       â”œâ”€â”€ commands/
â”‚       â”‚   â”œâ”€â”€ analyze.py              # /stock-moat analyze
â”‚       â”‚   â”œâ”€â”€ batch.py                # /stock-moat batch
â”‚       â”‚   â”œâ”€â”€ verify.py               # /stock-moat verify
â”‚       â”‚   â”œâ”€â”€ report.py               # /stock-moat report
â”‚       â”‚   â””â”€â”€ status.py               # /stock-moat status
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ excel_io.py             # Excel read/write
â”‚           â”œâ”€â”€ dart_api.py             # DART integration
â”‚           â”œâ”€â”€ kind_scraper.py         # KIND scraping
â”‚           â””â”€â”€ moat_scoring.py         # Moat framework
â””â”€â”€ workflows/
    â””â”€â”€ stock-moat-estimator/
        â”œâ”€â”€ single_stock_workflow.yml   # Single stock analysis
        â””â”€â”€ batch_workflow.yml          # Batch processing

scripts/
â””â”€â”€ stock_moat/
    â”œâ”€â”€ analyze_stock.py                # CLI entry point
    â”œâ”€â”€ batch_processor.py              # Batch executor
    â””â”€â”€ verification_queue.py           # Moat â‰¥4 re-verification

data/
â””â”€â”€ stock_moat/
    â”œâ”€â”€ .stock-moat-status.json         # Progress tracking
    â””â”€â”€ manual_review.json              # Failed stocks log
```

### 9.2 Key Implementation Files

#### `.agent/agents/stock-moat-estimator/agent.json`
```json
{
  "name": "stock-moat-estimator",
  "version": "1.0.0",
  "model": "claude-sonnet-4-5",
  "fallback_model": "claude-haiku-4-5",
  "max_tokens": 10000,
  "temperature": 0.3,
  "system_prompt_file": "system_prompt.md"
}
```

#### `.agent/skills/stock-moat/commands/analyze.py`
```python
"""
/stock-moat analyze {ticker} implementation
"""

def analyze_stock(ticker: str) -> dict:
    """
    Analyze single stock and fill missing fields

    Returns:
        {
            'ticker': '005930',
            'core_sector_top': 'ë°˜ë„ì²´',
            'core_sector_sub': 'ë©”ëª¨ë¦¬/ì‹œìŠ¤í…œë°˜ë„ì²´',
            'core_desc': '...',
            'í•´ìê°•ë„': 4,
            'í•´ìDESC': '...',
            'ê²€ì¦ìš©desc': '...'
        }
    """
    # 1. Load stock data
    stock = load_stock(ticker)

    # 2. Research workflow
    dart_data = fetch_dart(stock['corp_code'])
    kind_data = fetch_kind(ticker)

    # 3. Identify core business
    core_desc = identify_core_business(dart_data, kind_data)

    # 4. Classify sector
    sector_top, sector_sub = classify_sector(core_desc)

    # 5. Evaluate moat
    moat_result = evaluate_moat(dart_data, kind_data, sector_top)

    # 6. Re-verify if moat â‰¥ 4
    if moat_result['í•´ìê°•ë„'] >= 4:
        verification = deep_verify(ticker, moat_result)
        moat_result['ê²€ì¦ìš©desc'] = verification

    # 7. Write to Excel
    update_excel(ticker, {
        'core_sector_top': sector_top,
        'core_sector_sub': sector_sub,
        'core_desc': core_desc,
        **moat_result
    })

    return moat_result
```

---

## 10. Testing & Validation Strategy

### 10.1 Unit Testing

**Test Cases**:
1. Excel I/O: Read/write operations
2. DART API: Mock responses
3. Sector mapping: 229 categories validation
4. Moat scoring: Calculation logic
5. Error handling: Retry logic, fallbacks

**Test File**: `tests/test_stock_moat.py`

```python
def test_moat_calculation():
    scores = {
        'brand': 4,
        'cost': 3,
        'network': 2,
        'switching': 4,
        'regulatory': 5
    }
    result = calculate_moat_strength(scores)
    assert result == 4  # (18/5 = 3.6 â†’ round to 4)

def test_sector_mapping():
    business_desc = "ë°˜ë„ì²´ ë©”ëª¨ë¦¬ ì œì¡°"
    sector = map_to_sector(business_desc, taxonomy)
    assert sector == "ë°˜ë„ì²´"
```

### 10.2 Integration Testing

**Test Workflow**:
1. Test 5 representative stocks manually
2. Validate all fields filled correctly
3. Check moat scoring consistency
4. Verify re-verification for high moat stocks

**Test Stocks**:
- ì‚¼ì„±ì „ì (005930) - Large cap, high moat
- ë„¤ì˜¤ìœ„ì¦ˆ (095660) - Mid cap, low moat
- ì•Œí†¤ (123750) - Small cap, unclear business
- í˜„ëŒ€ì°¨ (005380) - Manufacturing
- ì¹´ì¹´ì˜¤ (035720) - Platform

### 10.3 Quality Assurance

**Manual Review** (20% sample):
- Random sample of 40 stocks (20% of 196)
- Expert review of moat scores
- Verify source citations
- Check sector classification accuracy

**Acceptance Criteria**:
- Sector classification accuracy: â‰¥ 95%
- Moat score consistency: â‰¥ 90% agreement with expert
- Source citation: 100% of stocks
- Re-verification: 100% for moat â‰¥ 4

---

## 11. Performance & Optimization

### 11.1 Speed Optimization

**Current Estimate**: 196 stocks Ã— 5 min = 980 min (16.3 hours)

**Optimization Tactics**:

1. **Parallel Processing** (10 concurrent)
   - Reduce to: 20 batches Ã— 5 min = 100 min (1.7 hours)

2. **Model Selection**:
   - Haiku for simple stocks (moat < 4): 2 min/stock
   - Sonnet for complex stocks: 5 min/stock
   - Expected mix: 70% Haiku, 30% Sonnet
   - New estimate: 196 Ã— (0.7 Ã— 2 + 0.3 Ã— 5) = 196 Ã— 2.9 = 568 min (9.5 hours)
   - With parallelization (Ã·10): **~60 min (1 hour)** âš¡

3. **Caching**:
   - Cache DART responses (same corp_code)
   - Cache sector mappings (common keywords)
   - Expected cache hit rate: 35%
   - Time savings: 35% Ã— 60 min = 21 min saved

**Final Estimate**: **40-50 minutes** for all 196 stocks (with re-verification: +2 hours)

**Total Time**: **2.5-3 hours** âš¡

### 11.2 Token Optimization

**Current Estimate**: 10,000 tokens/stock Ã— 196 = 1,960,000 tokens

**Optimization**:
- Use Haiku (cheaper) for 70% of stocks
- Cache common responses (sector taxonomy)
- Structured prompts (reduce redundancy)

**Token Budget**:
- Haiku: 137 stocks Ã— 5,000 tokens = 685,000 tokens
- Sonnet: 59 stocks Ã— 10,000 tokens = 590,000 tokens
- **Total**: ~1,275,000 tokens (35% savings)

---

## 12. Next Steps (Implementation Phase)

### Phase 1: Setup (2-3 hours)
1. Create agent directory structure
2. Write agent.json and system_prompt.md
3. Create skill.json and command stubs
4. Set up agent memory files

### Phase 2: Core Implementation (4-6 hours)
1. Implement Excel I/O (excel_io.py)
2. DART API integration (dart_api.py)
3. KIND scraping (kind_scraper.py)
4. Moat scoring logic (moat_scoring.py)
5. Single stock workflow (analyze.py)

### Phase 3: Batch Processing (2-3 hours)
1. Implement batch_processor.py
2. Checkpointing logic
3. Error handling & retry
4. Progress tracking

### Phase 4: Testing (2-3 hours)
1. Unit tests (5 stocks)
2. Integration test (batch of 10)
3. Quality validation

### Phase 5: Execution (3-4 hours)
1. Run batch processing (all 196 stocks)
2. Re-verification queue (moat â‰¥ 4)
3. Generate final report

**Total Development Time**: 10-15 hours (1.5-2 days)
**Total Execution Time**: 3-4 hours

---

## 13. Success Metrics (Design Phase)

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Completion Rate** | 100% (208/208) | Excel row count |
| **Moat Accuracy** | â‰¥ 90% | Expert review (40-stock sample) |
| **Sector Classification** | â‰¥ 95% | Taxonomy compliance check |
| **Re-verification** | 100% for moat â‰¥4 | ê²€ì¦ìš©desc filled |
| **Source Citations** | 100% | All stocks cite DART/KIND/IR |
| **Execution Time** | < 4 hours | Batch processing logs |
| **Token Usage** | < 1.5M tokens | API monitoring |
| **Error Rate** | < 5% | Failed stocks / total stocks |

---

## 14. Risks & Mitigation (Design Phase)

| Risk | Impact | Mitigation Strategy |
|------|--------|---------------------|
| DART API rate limiting | High | Exponential backoff, cache responses, use KIND fallback |
| Insufficient disclosure data | Medium | Use IR pages, Naver Finance; mark for manual review if needed |
| Sector taxonomy ambiguity | Medium | Fuzzy matching, manual review of edge cases (5%) |
| Moat scoring inconsistency | High | Detailed rubric, agent memory learning, expert review sample |
| Excel file corruption | Critical | Atomic writes with backup, test on copy first |
| Token budget overrun | Medium | Use Haiku for 70% of stocks, cache aggressively |

---

## Changelog

| Date | Author | Changes |
|------|--------|---------|
| 2026-02-09 | Claude Sonnet 4.5 | Initial design document created |
| 2026-02-09 | Claude Sonnet 4.5 | Added detailed agent spec, skill API, moat framework, implementation files |
| 2026-02-09 | Claude Sonnet 4.5 | Optimized timeline to 1.5-2 days (parallel processing) |

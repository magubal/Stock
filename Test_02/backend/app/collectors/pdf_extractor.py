from typing import List, Dict, Any
import asyncio
import aiohttp
from bs4 import BeautifulSoup
import re
from datetime import datetime
from urllib.parse import urljoin, urlparse
from .base import BaseCollector

class PDFReportCollector(BaseCollector):
    """PDF ë¦¬í¬íŠ¸ ìƒì„¸ ë‚´ìš© ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/pdf, application/octet-stream',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3'
        }
    
    async def collect(self) -> List[Dict[str, Any]]:
        """PDF ë¦¬í¬íŠ¸ URL ëª©ë¡ì—ì„œ ìƒì„¸ ë‚´ìš© ìˆ˜ì§‘"""
        # TODO: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìˆ˜ì§‘í•  ë¦¬í¬íŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        report_urls = [
            'https://www.miraeasset.com/resources/research/2023/ABC123.pdf',
            # ì‹¤ì œ URL ëª©ë¡ìœ¼ë¡œ ëŒ€ì²´ í•„ìš”
        ]
        
        reports = []
        
        for url in report_urls:
            try:
                report_data = await self.extract_pdf_content(url)
                if report_data:
                    reports.append(report_data)
                
                # ìš”ì²­ ê°„ ë”œë ˆì´
                await asyncio.sleep(1)
                
            except Exception as e:
                print(f"PDF ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨ {url}: {e}")
                continue
        
        return reports
    
    async def extract_pdf_content(self, pdf_url: str) -> Dict[str, Any]:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        async with aiohttp.ClientSession(headers=self.headers) as session:
            try:
                async with session.get(pdf_url) as response:
                    if response.status == 200:
                        # PDF ë‹¤ìš´ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        pdf_content = await response.read()
                        
                        # PyMuPDFë‚˜ pdfplumberë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë³„ë„ ì„¤ì¹˜ í•„ìš”)
                        text = await self.extract_text_from_pdf(pdf_content)
                        
                        return {
                            'pdf_url': pdf_url,
                            'content': text,
                            'extracted_at': datetime.now()
                        }
                    else:
                        print(f"PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status}")
                        return None
                        
            except Exception as e:
                print(f"PDF íŒŒì‹± ì‹¤íŒ¨: {e}")
                return None
    
    async def extract_text_from_pdf(self, pdf_content: bytes) -> str:
        """PDF ë°”ì´ë„ˆë¦¬ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        # TODO: PyMuPDF(fitz)ë‚˜ pdfplumber ì„¤ì¹˜ í›„ êµ¬í˜„
        # ì˜ˆì‹œ êµ¬ì¡°:
        try:
            import fitz  # PyMuPDF
            doc = fitz.open(stream=pdf_content, filetype="pdf")
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            return text
        except ImportError:
            print("âš ï¸ PyMuPDFê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install PyMuPDF í•„ìš”")
            return ""
        except Exception as e:
            print(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def parse_data(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """PDF ë‚´ìš©ì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ"""
        content = raw_data.get('content', '')
        
        # íˆ¬ìì˜ê²¬ ì¶”ì¶œ
        recommendation = self.extract_recommendation_from_text(content)
        
        # ëª©í‘œê°€ ì¶”ì¶œ
        target_price = self.extract_target_price_from_text(content)
        
        # í•µì‹¬ ë‚´ìš© ìš”ì•½
        summary = self.extract_summary(content)
        
        return {
            'content': content,
            'recommendation': recommendation,
            'target_price': target_price,
            'summary': summary,
            'pdf_url': raw_data.get('pdf_url'),
            'extracted_at': raw_data.get('extracted_at')
        }
    
    def extract_recommendation_from_text(self, text: str) -> str:
        """ë¦¬í¬íŠ¸ ë‚´ìš©ì—ì„œ íˆ¬ìì˜ê²¬ ì¶”ì¶œ"""
        recommendation_patterns = [
            r'íˆ¬ìì˜ê²¬[:\s]*([ê°€-í£]+)',
            r'ì˜ê²¬[:\s]*([ê°€-í£]+)',
            r'ì¶”ì²œ[:\s]*([ê°€-í£]+)',
            r'ë§¤ìˆ˜ê°•ë„[:\s]*([0-9]+)',
        ]
        
        for pattern in recommendation_patterns:
            match = re.search(pattern, text)
            if match:
                opinion = match.group(1)
                if 'ë§¤ìˆ˜' in opinion or 'ê°•ë§¤ìˆ˜' in opinion or 'Buy' in opinion:
                    return 'buy'
                elif 'ë§¤ë„' in opinion or 'ê°•ë§¤ë„' in opinion or 'Sell' in opinion:
                    return 'sell'
                elif 'ë³´ìœ ' in opinion or 'ì¤‘ë¦½' in opinion or 'Hold' in opinion:
                    return 'hold'
        
        return 'hold'  # ê¸°ë³¸ê°’
    
    def extract_target_price_from_text(self, text: str) -> float:
        """ë¦¬í¬íŠ¸ ë‚´ìš©ì—ì„œ ëª©í‘œê°€ ì¶”ì¶œ"""
        # ëª©í‘œê°€ ê´€ë ¨ íŒ¨í„´
        target_price_patterns = [
            r'ëª©í‘œê°€[:\s]*([0-9,]+)ì›',
            r'Target Price[:\s]*\$?([0-9,]+)',
            r'12ê°œì›” ëª©í‘œê°€[:\s]*([0-9,]+)ì›',
            r'B/S[:\s]*([0-9,]+)ì›',  # Buy/Sell price
        ]
        
        for pattern in target_price_patterns:
            matches = re.findall(pattern, text)
            if matches:
                price_str = matches[0].replace(',', '')
                try:
                    return float(price_str)
                except ValueError:
                    continue
        
        return None
    
    def extract_summary(self, text: str) -> str:
        """ë¦¬í¬íŠ¸ ë‚´ìš© ìš”ì•½"""
        # ì²« ë¬¸ë‹¨ì´ë‚˜ ì£¼ìš” ì„¹ì…˜ ì¶”ì¶œ
        lines = text.split('\n')
        summary_lines = []
        
        for line in lines:
            line = line.strip()
            if len(line) > 20 and not line.startswith('â–²'):  # ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥
                summary_lines.append(line)
                if len(summary_lines) >= 3:  # ì²˜ìŒ 3ë¬¸ì¥
                    break
        
        return ' '.join(summary_lines) if summary_lines else text[:200]
    
    async def save_to_db(self, data: Dict[str, Any]):
        """ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (êµ¬í˜„ ì˜ˆì •)"""
        # TODO: ê¸°ì¡´ ë¦¬í¬íŠ¸ ë ˆì½”ë“œ ì—…ë°ì´íŠ¸
        print(f"ğŸ’¾ ë¦¬í¬íŠ¸ ë‚´ìš© ì €ì¥ ì˜ˆì •: {data.get('summary', '')[:50]}...")
        pass
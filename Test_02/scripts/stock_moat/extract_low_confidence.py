"""
Extract Low-Confidence Stocks for Manual Review
Creates a separate list of stocks with confidence < 50%
"""

import sys
import os
import json

# Fix encoding
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# Add project root
project_root = "F:/PSJ/AntigravityWorkPlace/Stock/Test_02"
sys.path.insert(0, f"{project_root}/.agent/skills/stock-moat/utils")

from excel_io import ExcelIO
import pandas as pd


def extract_low_confidence():
    """Extract stocks with low confidence (ê¸°íƒ€/ë¯¸ë¶„ë¥˜) for manual review"""

    excel_path = f"{project_root}/data/ask/stock_core_master_v2_korean_taxonomy_2026-01-30_ìš”ì²­ìš©_011.xlsx"
    excel_io = ExcelIO(excel_path)

    print(f"\n{'='*60}")
    print(f"ðŸ“‹ Extracting Low-Confidence Stocks")
    print(f"{'='*60}\n")

    # Load data
    df = excel_io.load_stock_data()

    # Find low-confidence stocks (ê¸°íƒ€/ë¯¸ë¶„ë¥˜)
    low_confidence = df[
        (df['í•´ìžê°•ë„'].notna()) &  # Analyzed
        (
            (df['core_sector_top'] == 'ê¸°íƒ€') |
            (df['core_sector_sub'] == 'ë¯¸ë¶„ë¥˜')
        )
    ].copy()

    print(f"Found {len(low_confidence)} low-confidence stocks\n")

    # Group by pattern
    categories = {
        'ì œì¡°ì—…': [],
        'ì œì§€/íŽ„í”„': [],
        'ì—¬í–‰/ê´€ê´‘': [],
        'í™”ìž¥í’ˆ/ë·°í‹°': [],
        'ì—”í„°í…Œì¸ë¨¼íŠ¸': [],
        'ê¸°íƒ€': []
    }

    for idx, stock in low_confidence.iterrows():
        ticker = stock['ticker']
        name = stock['name']

        # Pattern matching for categorization
        if any(keyword in name for keyword in ['ì œì§€', 'íŒì§€', 'íŽ„í”„', 'P&P', 'PNS', 'SP']):
            categories['ì œì¡°ì—…'].append({'ticker': ticker, 'name': name})
        elif any(keyword in name for keyword in ['íˆ¬ì–´', 'ì—¬í–‰', 'Cruise', 'Carnival', 'Royal', 'Norwegian']):
            categories['ì—¬í–‰/ê´€ê´‘'].append({'ticker': ticker, 'name': name})
        elif any(keyword in name for keyword in ['ë§ˆë…€ê³µìž¥', 'ë·°í‹°', 'ì½”ë””', 'ì•„ëª¨ë ˆ', 'ì½”ë¦¬ì•„ë‚˜', 'ì—ì´í”¼ì•Œ', 'ì‚ì•„', 'ë‹¬ë°”', 'ì•„ë¡œë§ˆí‹°ì¹´']):
            categories['í™”ìž¥í’ˆ/ë·°í‹°'].append({'ticker': ticker, 'name': name})
        elif any(keyword in name for keyword in ['í•˜ì´ë¸Œ', 'HYBE', 'ì—ìŠ¤ì— ', 'SM', 'ë¯¸ë””ì–´', 'TJ']):
            categories['ì—”í„°í…Œì¸ë¨¼íŠ¸'].append({'ticker': ticker, 'name': name})
        else:
            categories['ê¸°íƒ€'].append({'ticker': ticker, 'name': name})

    # Display results
    for category, stocks in categories.items():
        if len(stocks) > 0:
            print(f"\n### {category} ({len(stocks)}ê°œ)")
            print(f"{'â”€'*60}")
            for stock in stocks[:10]:  # Show first 10
                print(f"  {stock['ticker']}: {stock['name']}")
            if len(stocks) > 10:
                print(f"  ... and {len(stocks) - 10} more")

    # Save to JSON
    output_path = f"{project_root}/data/stock_moat/low_confidence_stocks.json"
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    output = {
        'total_count': len(low_confidence),
        'categories': {
            category: [
                {
                    'ticker': stock['ticker'],
                    'name': stock['name'],
                    'current_classification': f"{df[df['ticker'] == stock['ticker']].iloc[0]['core_sector_top']}/{df[df['ticker'] == stock['ticker']].iloc[0]['core_sector_sub']}"
                }
                for stock in stocks
            ]
            for category, stocks in categories.items() if len(stocks) > 0
        },
        'generated_at': pd.Timestamp.now().isoformat()
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\n{'='*60}")
    print(f"âœ… Saved to: {output_path}")
    print(f"{'='*60}\n")

    return output


if __name__ == "__main__":
    result = extract_low_confidence()
